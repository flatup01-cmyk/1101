"""
Cloud Functions: å‹•ç”»è§£æ + Dify + LINEé€£æºï¼ˆè¦å¡åŒ–ç‰ˆï¼‰

ã€ç¥ã®ä¿¡é ¼æ€§ã€‘100ä¸‡å›ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ã€ã‚¨ãƒ©ãƒ¼ã¯1å›ã‚‚è¨±ã•ãªã„ã€‚

å®Ÿè£…å†…å®¹ï¼š
- Secret Managerã‹ã‚‰æ©Ÿå¯†æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
- ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚’ä¿è¨¼
- æŒ‡æ•°é–¢æ•°çš„ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤å‡¦ç†
- å†ªç­‰æ€§ç¢ºä¿ï¼ˆé€šçŸ¥æ¸ˆã¿ãƒ•ãƒ©ã‚°ï¼‰
- Cloud Loggingé€£æºï¼ˆã‚¢ãƒ©ãƒ¼ãƒˆï¼‰
"""

import os
import json
import tempfile
import base64
import requests
import logging
import hashlib
import traceback
import cv2
from datetime import datetime
from google.cloud import storage, firestore
from google.cloud.secretmanager_v1 import SecretManagerServiceClient
from tenacity import retry, stop_after_attempt, wait_exponential, RetryError
from analyze import analyze_kickboxing_form
from rate_limiter import check_rate_limit

# Firebase Functions Framework
import functions_framework

# Cloud Loggingè¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Client Initialization (Lazy Loading) ---
# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯é–¢æ•°å†…ã§åˆæœŸåŒ–ã•ã‚Œã‚‹ãŸã‚ã€ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å›é¿
storage_client = None
db = None

def get_storage_client():
    """Storageã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
    global storage_client
    if storage_client is None:
        storage_client = storage.Client()
    return storage_client

def get_firestore_client():
    """Firestoreã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
    global db
    if db is None:
        db = firestore.Client()
    return db

_secret_client = None
def get_secret_client():
    global _secret_client
    if _secret_client is None:
        _secret_client = SecretManagerServiceClient()
    return _secret_client

# --- Secret Manager Access Function ---
def access_secret_version(secret_id, project_id, version_id="latest"):
    """
    Secret Managerã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’å–å¾—
    
    Args:
        secret_id: ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆå
        project_id: GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
        version_id: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: latestï¼‰
    
    Returns:
        str: ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®å€¤
    """
    try:
        client = get_secret_client()
        name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
        response = client.access_secret_version(name=name)
        return response.payload.data.decode('UTF-8')
    except Exception as e:
        logger.error(f"Secret Managerèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({secret_id}): {str(e)}")
        raise

# --- Load Secrets at Runtime ---
PROJECT_ID = os.environ.get('GCP_PROJECT', 'aikaapp-584fa')

# LINEã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¯Secret Managerã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆæœ€å„ªå…ˆãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ï¼‰


# Dify APIè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ»å¿…é ˆï¼‰
DIFY_API_ENDPOINT = os.environ.get('DIFY_API_ENDPOINT', 'https://api.dify.ai/v1/chat-messages')
DIFY_API_KEY = os.environ.get('DIFY_API_KEY')

# ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼ï¼ˆè­¦å‘Šã®ã¿ã€é–¢æ•°ã®å®Ÿè¡Œã¯ç¶™ç¶šï¼‰
if not DIFY_API_KEY:
    logger.warning("âš ï¸ WARNING: DIFY_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    logger.warning("Firebase Console â†’ Functions â†’ ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã—ã¦ãã ã•ã„")
    logger.warning("Dify APIé€£æºã¯æ©Ÿèƒ½ã—ã¾ã›ã‚“ãŒã€å‹•ç”»è§£æã¯ç¶™ç¶šã•ã‚Œã¾ã™")
    # æœ¬ç•ªç’°å¢ƒã§ã¯ç’°å¢ƒå¤‰æ•°ãŒå¿…é ˆã ãŒã€é–¢æ•°ã®å®Ÿè¡Œã¯ç¶™ç¶šï¼ˆã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã—ãªã„ï¼‰


# --- MCPé€£æºé–¢æ•° ---
def call_dify_via_mcp(scores, user_id):
    """
    MCPã‚¹ã‚¿ã‚¤ãƒ«ã§Dify APIã‚’å‘¼ã³å‡ºã—ã¦AIKAã®ã‚»ãƒªãƒ•ã‚’ç”Ÿæˆ
    
    MCPãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«æº–æ‹ ã—ãŸå½¢å¼ã§Dify APIã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚
    å®Ÿéš›ã«ã¯Difyã®æ¨™æº–REST APIã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€MCPäº’æ›ã®å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã—ã¾ã™ã€‚
    
    Args:
        scores: è§£æã‚¹ã‚³ã‚¢ï¼ˆdictï¼‰
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
    
    Returns:
        str: AIKAã®ã‚»ãƒªãƒ•ã€ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯None
    """
    global DIFY_API_ENDPOINT, DIFY_API_KEY
    
    if not DIFY_API_ENDPOINT or not DIFY_API_KEY:
        logger.error("âŒ Dify APIè¨­å®šãŒä¸å®Œå…¨ã§ã™")
        logger.error(f"DIFY_API_ENDPOINT: {'è¨­å®šæ¸ˆã¿' if DIFY_API_ENDPOINT else 'æœªè¨­å®š'}")
        logger.error(f"DIFY_API_KEY: {'è¨­å®šæ¸ˆã¿' if DIFY_API_KEY else 'æœªè¨­å®š'}")
        logger.error("Firebase Console â†’ Functions â†’ ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã—ã¦ãã ã•ã„")
        return None
    
    try:
        headers = {
            'Authorization': f'Bearer {DIFY_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        # MCPãƒ—ãƒ­ãƒˆã‚³ãƒ«å½¢å¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        # Difyã®æ¨™æº–APIã‚’ä½¿ç”¨ã—ã€MCPäº’æ›ã®å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
        mcp_payload = {
            # MCPã‚¹ã‚¿ã‚¤ãƒ«: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—å½¢å¼
            'method': 'chat',
            'params': {
                'inputs': {
                    'punch_speed_score': str(scores.get('punch_speed', 0)),
                    'guard_stability_score': str(scores.get('guard_stability', 0)),
                    'kick_height_score': str(scores.get('kick_height', 0)),
                    'core_rotation_score': str(scores.get('core_rotation', 0))
                },
                'user': user_id,
                'response_mode': 'blocking'
            }
        }
        
        # å®Ÿéš›ã«ã¯Difyã®æ¨™æº–APIã‚’ä½¿ç”¨
        # MCPã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–å½¢å¼ã«å¤‰æ›
        dify_payload = {
            'inputs': mcp_payload['params']['inputs'],
            'user': mcp_payload['params']['user'],
            'response_mode': mcp_payload['params']['response_mode']
        }
        
        logger.info(f"ğŸ“¤ Dify MCPå‘¼ã³å‡ºã—: {json.dumps(dify_payload, ensure_ascii=False)}")
        
        response = requests.post(
            DIFY_API_ENDPOINT,
            headers=headers,
            json=dify_payload,
            timeout=30
        )
        
        response.raise_for_status()
        result = response.json()
        
        # MCPã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
        # Difyã®æ¨™æº–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        message = result.get('answer', result.get('text', ''))
        
        # MCPã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã«å¤‰æ›ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
        mcp_response = {
            'result': {
                'content': message,
                'format': 'text'
            }
        }
        
        if message:
            logger.info(f"âœ… Dify MCPæˆåŠŸ: {message[:50]}...")
            logger.debug(f"MCPãƒ¬ã‚¹ãƒãƒ³ã‚¹: {json.dumps(mcp_response, ensure_ascii=False)}")
            return message
        else:
            logger.warning("âš ï¸ Dify MCPã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            logger.debug(f"Difyãƒ¬ã‚¹ãƒãƒ³ã‚¹: {json.dumps(result, ensure_ascii=False)}")
            return None
            
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ Dify MCP APIã‚¨ãƒ©ãƒ¼: {str(e)}")
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return None
    except Exception as e:
        logger.error(f"âŒ Dify MCPå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        return None


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    reraise=True
)
def send_line_message_with_retry(user_id, message, unique_id):
    """
    LINE Messaging APIã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ï¼ˆæŒ‡æ•°é–¢æ•°çš„ãƒãƒƒã‚¯ã‚ªãƒ•ãƒ»ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
    
    Args:
        user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        message: é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        unique_id: å†ªç­‰æ€§ç¢ºä¿ã®ãŸã‚ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ID
    
    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆTrue
    """
    try:
        # Secret Managerã‹ã‚‰LINEã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
        LINE_CHANNEL_ACCESS_TOKEN = access_secret_version(
            "LINE_CHANNEL_ACCESS_TOKEN",
            PROJECT_ID
        )
        
        if not LINE_CHANNEL_ACCESS_TOKEN:
            logger.error("âŒ LINEã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        # ã€å†ªç­‰æ€§ç¢ºä¿ã€‘æ—¢ã«é€šçŸ¥æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        db = get_firestore_client()
        notification_doc = db.collection('video_jobs').document(unique_id).get()
        if notification_doc.exists:
            notification_data = notification_doc.to_dict()
            if notification_data.get('notification_sent', False):
                logger.info(f"â­ï¸ æ—¢ã«é€šçŸ¥æ¸ˆã¿: {unique_id}")
                return True
        
        # LINE APIã«é€ä¿¡
        url = 'https://api.line.me/v2/bot/message/push'
        headers = {
            'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}',
            'Content-Type': 'application/json'
        }
        data = {
            'to': user_id,
            'messages': [
                {
                    'type': 'text',
                    'text': message
                }
            ]
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        
        # ã€å†ªç­‰æ€§ç¢ºä¿ã€‘é€šçŸ¥æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
        db = get_firestore_client()
        db.collection('video_jobs').document(unique_id).update({
            'notification_sent': True,
            'notification_sent_at': firestore.SERVER_TIMESTAMP,
            'updated_at': firestore.SERVER_TIMESTAMP
        })
        
        logger.info(f"âœ… LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡æˆåŠŸ: {user_id}")
        return True
        
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 401:
            logger.error(f"âŒ LINEèªè¨¼ã‚¨ãƒ©ãƒ¼ï¼ˆ401ï¼‰: ãƒˆãƒ¼ã‚¯ãƒ³ãŒç„¡åŠ¹ã§ã™")
        elif e.response.status_code == 400:
            logger.error(f"âŒ LINEãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ï¼ˆ400ï¼‰: {e.response.text}")
        else:
            logger.error(f"âŒ LINE API HTTPã‚¨ãƒ©ãƒ¼: {e.response.status_code}")
        raise
    except RetryError:
        # 3å›ãƒªãƒˆãƒ©ã‚¤ã—ã¦ã‚‚å¤±æ•—ã—ãŸå ´åˆ
        logger.error(f"âŒ FATAL: LINE APIé€ä¿¡ã«3å›å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_id}ï¼‰")
        
        # ã€Cloud Loggingé€£æºã€‘ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
        alert_payload = {
            "severity": "ERROR",
            "message": "CRITICAL: LINE APIé€ä¿¡å¤±æ•—ï¼ˆ3å›ãƒªãƒˆãƒ©ã‚¤å¾Œï¼‰",
            "user_id": user_id,
            "unique_id": unique_id,
            "timestamp": datetime.utcnow().isoformat()
        }
        logger.error(json.dumps(alert_payload))
        
        raise
    except Exception as e:
        logger.error(f"âŒ LINE APIé€ä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise


def process_video(data, context):
    """
    Firebase Storageã®ãƒˆãƒªã‚¬ãƒ¼ã§å‘¼ã°ã‚Œã‚‹é–¢æ•°ï¼ˆè¦å¡åŒ–ç‰ˆï¼‰
    
    ã€ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã€‘ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§å®Œå…¨ä¿è¨¼
    ã€å†ªç­‰æ€§ã€‘é€šçŸ¥æ¸ˆã¿ãƒ•ãƒ©ã‚°ã§é‡è¤‡å®Ÿè¡Œã‚’å®Œå…¨é˜²æ­¢
    ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€‘æŒ‡æ•°é–¢æ•°çš„ãƒãƒƒã‚¯ã‚ªãƒ•ã§ç¢ºå®Ÿã«é€ä¿¡
    
    Args:
        data: ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒå…¥ã£ã¦ã„ã‚‹ï¼‰
        context: ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    """
    try:
        logger.info("ğŸ“ process_videoé–¢æ•°é–‹å§‹")
        logger.info(f"ğŸ“ å—ä¿¡ãƒ‡ãƒ¼ã‚¿å‹: {type(data)}")
        logger.info(f"ğŸ“ å—ä¿¡ãƒ‡ãƒ¼ã‚¿å†…å®¹: {json.dumps(data, ensure_ascii=False, default=str) if isinstance(data, dict) else str(data)[:200]}")
        
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
        if isinstance(data, str):
            logger.info("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãŒæ–‡å­—åˆ—å‹ã§ã™ã€‚ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã¾ã™...")
            try:
                data = json.loads(base64.b64decode(data).decode('utf-8'))
                logger.info("ğŸ“ Base64ãƒ‡ã‚³ãƒ¼ãƒ‰â†’JSONãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
            except (json.JSONDecodeError, UnicodeDecodeError, ValueError) as e:
                try:
                    data = json.loads(data)
                    logger.info("ğŸ“ JSONæ–‡å­—åˆ—ã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
                except json.JSONDecodeError:
                    logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    return {"status": "error", "reason": "invalid data format"}
        
        file_path = data.get('name') or data.get('file')
        bucket_name = data.get('bucket', os.environ.get('STORAGE_BUCKET', 'aikaapp-584fa.firebasestorage.app'))
        
        logger.info(f"ğŸ“ å‡¦ç†é–‹å§‹: {file_path} (bucket: {bucket_name})")
    
        # videos/ã§å§‹ã¾ã‚‰ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç„¡è¦–
        if not file_path or not file_path.startswith('videos/'):
            logger.info(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: videos/ã§å§‹ã¾ã‚‰ãªã„ãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
            return {"status": "skipped", "reason": "not a video file"}
    
        # ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒå¯¾ç­–
        # æ³¨æ„: osã¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§æ—¢ã«importã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€é–¢æ•°å†…ã§import os.pathã¯ä¸è¦
        # é–¢æ•°å†…ã§import os.pathã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€osãŒãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã¨ã—ã¦æ‰±ã‚ã‚Œã€UnboundLocalErrorãŒç™ºç”Ÿã™ã‚‹
        normalized_path = os.path.normpath(file_path)
        if not normalized_path.startswith('videos/'):
            logger.error(f"âŒ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ä¸æ­£ãªãƒ‘ã‚¹: {file_path}")
            return {"status": "error", "reason": "invalid path"}
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¨jobIdã‚’æŠ½å‡º
        # ãƒ‘ã‚¹æ§‹é€ : videos/{userId}/{jobId}/{fileName}
        path_parts = file_path.split('/')
        if len(path_parts) < 4:
            logger.error(f"âŒ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹æ§‹é€ ãŒä¸æ­£: {file_path}")
            return {"status": "error", "reason": "invalid path structure"}
        
        user_id = path_parts[1]
        job_id = path_parts[2] if len(path_parts) >= 3 else None
        
        logger.info(f"ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼IDæŠ½å‡º: {user_id}, JobIDæŠ½å‡º: {job_id}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®æ¤œè¨¼
        if not user_id or not user_id.replace('-', '').replace('_', '').isalnum():
            logger.error(f"âŒ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ä¸æ­£ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_id}")
            return {"status": "error", "reason": "invalid user id"}
        
        # ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆãƒã‚§ãƒƒã‚¯
        logger.info(f"ğŸ“ ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆãƒã‚§ãƒƒã‚¯é–‹å§‹: {user_id}")
        is_allowed, rate_limit_message = check_rate_limit(user_id, 'upload_video')
        if not is_allowed:
            logger.warning(f"âŒ ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆè¶…é: {user_id} - {rate_limit_message}")
            try:
                # ç°¡æ˜“çš„ãªLINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼‰
                LINE_CHANNEL_ACCESS_TOKEN = access_secret_version("LINE_CHANNEL_ACCESS_TOKEN", PROJECT_ID)
                if LINE_CHANNEL_ACCESS_TOKEN:
                    requests.post(
                        'https://api.line.me/v2/bot/message/push',
                        headers={'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}', 'Content-Type': 'application/json'},
                        json={'to': user_id, 'messages': [{'type': 'text', 'text': f"ã”ã‚ã‚“ã‚ãã°ã›ã€‚{rate_limit_message}"}]},
                        timeout=10
                    )
            except Exception as notify_error:
                logger.error(f"ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {str(notify_error)}")
            return {"status": "rate_limit_exceeded", "reason": rate_limit_message}
        
        logger.info(f"âœ“ ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆãƒã‚§ãƒƒã‚¯é€šé: {user_id}")
    
        # ã€å†ªç­‰æ€§ç¢ºä¿ã€‘Firestoreã§å‡¦ç†æ¸ˆã¿ãƒã‚§ãƒƒã‚¯
        logger.info(f"ğŸ“ å†ªç­‰æ€§ãƒã‚§ãƒƒã‚¯é–‹å§‹: jobId={job_id}")
        # jobIdãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–
        db = get_firestore_client()
        if job_id:
            processing_doc_ref = db.collection('video_jobs').document(job_id)
            unique_id = job_id
        else:
            file_hash = hashlib.md5(file_path.encode()).hexdigest()
            processing_doc_ref = db.collection('video_processing').document(file_hash)
            unique_id = file_hash
        
        # ã€å†ªç­‰æ€§ç¢ºä¿ã€‘ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§å‡¦ç†æ¸ˆã¿ãƒã‚§ãƒƒã‚¯
        @firestore.transactional
        def check_and_mark_processing(transaction, processing_doc_ref, job_id, file_path, user_id):
            """ã‚¢ãƒˆãƒŸãƒƒã‚¯ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§å‡¦ç†æ¸ˆã¿ãƒã‚§ãƒƒã‚¯"""
            doc = processing_doc_ref.get(transaction=transaction)
            if doc.exists:
                doc_data = doc.to_dict()
                current_status = doc_data.get('status')
                if current_status == 'completed':
                    logger.info(f"âœ… æ—¢ã«å‡¦ç†æ¸ˆã¿ï¼ˆå†ªç­‰æ€§ç¢ºä¿ï¼‰: {file_path}")
                    return False  # å‡¦ç†æ¸ˆã¿â†’ã‚¹ã‚­ãƒƒãƒ—
                elif current_status == 'processing':
                    logger.warning(f"âš ï¸ å‡¦ç†ä¸­ï¼ˆé‡è¤‡å®Ÿè¡Œé˜²æ­¢ï¼‰: {file_path}")
                    return False  # å‡¦ç†ä¸­â†’ã‚¹ã‚­ãƒƒãƒ—
            # å‡¦ç†é–‹å§‹ã‚’ãƒãƒ¼ã‚¯ï¼ˆã‚¢ãƒˆãƒŸãƒƒã‚¯ï¼‰
            if job_id:
                # video_jobsã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å ´åˆ
                transaction.update(processing_doc_ref, {
                    'status': 'processing',
                    'updated_at': firestore.SERVER_TIMESTAMP
                })
            else:
                # video_processingã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å ´åˆ
                transaction.set(processing_doc_ref, {
                    'status': 'processing',
                    'file_path': file_path,
                    'user_id': user_id,
                    'started_at': firestore.SERVER_TIMESTAMP,
                    'updated_at': firestore.SERVER_TIMESTAMP
                })
            return True  # æ–°è¦å‡¦ç†
        
        try:
            is_new = check_and_mark_processing(processing_doc_ref, job_id, file_path, user_id)
            if not is_new:
                logger.info("âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: æ—¢ã«å‡¦ç†æ¸ˆã¿ã¾ãŸã¯å‡¦ç†ä¸­")
                return {"status": "skipped", "reason": "already processed or processing"}
            logger.info("ğŸ“ æ–°è¦å‡¦ç†ã¨ã—ã¦ãƒãƒ¼ã‚¯å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¤±æ•—: {str(e)}")
            traceback.print_exc()
            return {"status": "error", "reason": "transaction failed"}
        
        # 2. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        logger.info(f"ğŸ“ å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {file_path}")
        storage_client = get_storage_client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(file_path)
        
        temp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:
                temp_path = temp_file.name
                blob.download_to_filename(temp_path)
                logger.info(f"ğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {temp_path}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ100MBåˆ¶é™ï¼‰
            file_size = os.path.getsize(temp_path)
            max_size = 100 * 1024 * 1024  # 100MB
            if file_size > max_size:
                logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¶…é: {file_size / 1024 / 1024:.2f}MB > 100MB")
                try:
                    # ç°¡æ˜“çš„ãªLINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼‰
                    LINE_CHANNEL_ACCESS_TOKEN = access_secret_version("LINE_CHANNEL_ACCESS_TOKEN", PROJECT_ID)
                    if LINE_CHANNEL_ACCESS_TOKEN:
                        requests.post(
                            'https://api.line.me/v2/bot/message/push',
                            headers={'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}', 'Content-Type': 'application/json'},
                            json={'to': user_id, 'messages': [{'type': 'text', 'text': "ã”ã‚ã‚“ã‚ãã°ã›ã€‚å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã‚‹ã‚ï¼ˆ100MBä»¥ä¸‹ã«åã‚ã¦ï¼‰ã€‚"}]},
                            timeout=10
                        )
                except Exception:
                    pass
                # Firestoreã‚’æ›´æ–°ï¼ˆã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ï¼‰
                processing_doc_ref.update({
                    'status': 'error',
                    'error_message': 'file size too large',
                    'updated_at': firestore.SERVER_TIMESTAMP
                })
                return {"status": "error", "reason": "file size too large"}
            
            # å‹•ç”»ã®é•·ã•ãƒã‚§ãƒƒã‚¯ï¼ˆ20ç§’åˆ¶é™ï¼‰
            cap = cv2.VideoCapture(temp_path)
            if not cap.isOpened():
                logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {temp_path}")
                cap.release()
                processing_doc_ref.update({
                    'status': 'error',
                    'error_message': 'cannot open video file',
                    'updated_at': firestore.SERVER_TIMESTAMP
                })
                return {"status": "error", "reason": "cannot open video file"}
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
            cap.release()
            
            if fps > 0:
                duration = frame_count / fps
                if duration > 20:
                    logger.error(f"âŒ å‹•ç”»ã®é•·ã•è¶…é: {duration:.2f}ç§’ > 20ç§’")
                    try:
                        # ç°¡æ˜“çš„ãªLINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼‰
                        LINE_CHANNEL_ACCESS_TOKEN = access_secret_version("LINE_CHANNEL_ACCESS_TOKEN", PROJECT_ID)
                        if LINE_CHANNEL_ACCESS_TOKEN:
                            requests.post(
                                'https://api.line.me/v2/bot/message/push',
                                headers={'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}', 'Content-Type': 'application/json'},
                                json={'to': user_id, 'messages': [{'type': 'text', 'text': "ã”ã‚ã‚“ã‚ãã°ã›ã€‚å‹•ç”»ãŒé•·ã™ãã‚‹ã‚ï¼ˆ20ç§’ä»¥å†…ã«åã‚ã¦ï¼‰ã€‚"}]},
                                timeout=10
                            )
                    except Exception:
                        pass
                    processing_doc_ref.update({
                        'status': 'error',
                        'error_message': 'video duration too long',
                        'updated_at': firestore.SERVER_TIMESTAMP
                    })
                    return {"status": "error", "reason": "video duration too long"}
            else:
                logger.warning("âš ï¸ FPSãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å‹•ç”»ã®é•·ã•ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                
        except Exception as download_error:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(download_error)}")
            processing_doc_ref.update({
                'status': 'error',
                'error_message': 'download failed',
                'updated_at': firestore.SERVER_TIMESTAMP
            })
            return {"status": "error", "reason": "download failed"}
        
        try:
            # 3. å‹•ç”»è§£æã‚’å®Ÿè¡Œ
            logger.info(f"ğŸ“ å‹•ç”»è§£æé–‹å§‹: {temp_path}")
            analysis_result = analyze_kickboxing_form(temp_path)
            logger.info(f"ğŸ“ è§£æçµæœ: {json.dumps(analysis_result, ensure_ascii=False)}")
            
            if analysis_result['status'] != 'success':
                logger.error(f"âŒ è§£æå¤±æ•—: {analysis_result.get('error_message', 'unknown error')}")
                processing_doc_ref.update({
                    'status': 'error',
                    'error_message': analysis_result.get('error_message', 'analysis failed'),
                    'updated_at': firestore.SERVER_TIMESTAMP
                })
                return analysis_result
            
            # 4. MCPã‚¹ã‚¿ã‚¤ãƒ«ã§Dify APIã«é€ä¿¡ã—ã¦AIKAã®ã‚»ãƒªãƒ•ã‚’ç”Ÿæˆ
            logger.info(f"ğŸ“ Dify APIå‘¼ã³å‡ºã—é–‹å§‹: user_id={user_id}")
            aika_message = call_dify_via_mcp(analysis_result['scores'], user_id)
            
            if not aika_message:
                logger.warning("âš ï¸ Dify MCPã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨
                aika_message = "â€¦åˆ¥ã«ã€ã‚¢ãƒ³ã‚¿ã®å‹•ç”»ã‚’è§£æã—ã¦ã‚„ã£ã¦ã‚‚ã„ã„ã‘ã©ï¼Ÿ"
            
            # 5. LINE Messaging APIã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é€ä¿¡ï¼ˆæŒ‡æ•°é–¢æ•°çš„ãƒãƒƒã‚¯ã‚ªãƒ•ãƒ»ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
            logger.info(f"ğŸ“ LINEé€ä¿¡é–‹å§‹: user_id={user_id}")
            try:
                send_line_message_with_retry(user_id, aika_message, unique_id)
                logger.info(f"âœ… LINEé€ä¿¡æˆåŠŸ: user_id={user_id}")
            except Exception as send_error:
                logger.error(f"âŒ LINEé€ä¿¡ã‚¨ãƒ©ãƒ¼ï¼ˆãƒªãƒˆãƒ©ã‚¤å¾Œã‚‚å¤±æ•—ï¼‰: {str(send_error)}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã¯ç¶™ç¶šï¼ˆãƒ­ã‚°ã«è¨˜éŒ²æ¸ˆã¿ï¼‰
            
            # ã€ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã€‘Firestoreã‚’æ›´æ–°ï¼ˆåˆ†æçµæœã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰
            logger.info(f"ğŸ“ Firestoreæ›´æ–°é–‹å§‹: unique_id={unique_id}")
            processing_doc_ref.update({
                'status': 'completed',
                'analysis_result': analysis_result['scores'],
                'aika_message': aika_message,
                'completed_at': firestore.SERVER_TIMESTAMP,
                'updated_at': firestore.SERVER_TIMESTAMP
            })
            
            logger.info(f"âœ… å‡¦ç†å®Œäº†: {file_path} (åˆ†æçµæœã‚’Firestoreã«ä¿å­˜)")
            
            return {
                "status": "success",
                "analysis": analysis_result['scores']
            }
            
        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
            logger.error(f"âŒ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
            
            # ã€Cloud Loggingé€£æºã€‘ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
            alert_payload = {
                "severity": "ERROR",
                "message": f"CRITICAL: å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼ - {file_path}",
                "user_id": user_id,
                "file_path": file_path,
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }
            logger.error(json.dumps(alert_payload))
            
            # Firestoreã‚’æ›´æ–°ï¼ˆã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ï¼‰
            processing_doc_ref.update({
                'status': 'error',
                'error_message': str(e),
                'updated_at': firestore.SERVER_TIMESTAMP
            })
            
            return {"status": "failure", "error_message": str(e)}
        
        finally:
            # 8. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if temp_path and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                    logger.info(f"ğŸ“ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {temp_path}")
                except Exception as cleanup_error:
                    logger.error(f"âŒ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(cleanup_error)}")
    
    except Exception as e:
        logger.error(f"âŒ process_videoå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        logger.error(f"âŒ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
        return {"status": "error", "reason": str(e)}





# Firebase Storage ãƒˆãƒªã‚¬ãƒ¼é–¢æ•°ï¼ˆCloudEventå½¢å¼ãƒ»Cloud Storage v2ä»•æ§˜å¯¾å¿œï¼‰
@functions_framework.cloud_event
def process_video_trigger(cloud_event):
    """
    Firebase Storageã®CloudEventãƒˆãƒªã‚¬ãƒ¼ï¼ˆCloud Storage v2ä»•æ§˜å¯¾å¿œï¼‰
    
    Storageã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹ã¨è‡ªå‹•ã§å‘¼ã°ã‚Œã¾ã™
    """
    # CloudEventã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å±æ€§ã‚’å®‰å…¨ã«å–å¾—ï¼ˆè¾æ›¸å½¢å¼ã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®ä¸¡æ–¹ã«å¯¾å¿œï¼‰
    try:
        logger.info("=" * 80)
        logger.info("ğŸ”” CloudEventå—ä¿¡é–‹å§‹")
        logger.info(f"ğŸ“¦ CloudEventå…¨ä½“ã®å‹: {type(cloud_event)}")
        logger.info(f"ğŸ“¦ CloudEventå…¨ä½“ã®å†…å®¹ï¼ˆæœ€åˆã®1000æ–‡å­—ï¼‰: {str(cloud_event)[:1000]}")
        
        # CloudEventã®å±æ€§ã‚’å–å¾—ï¼ˆè¾æ›¸å½¢å¼ã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®ä¸¡æ–¹ã«å¯¾å¿œï¼‰
        if isinstance(cloud_event, dict):
            attributes = cloud_event.get('attributes', {})
            if not isinstance(attributes, dict):
                attributes = {}
            event_type = attributes.get('type') or cloud_event.get('type', 'unknown')
            event_source = attributes.get('source') or cloud_event.get('source', 'unknown')
            event_data = cloud_event.get('data') or cloud_event.get('payload')
        else:
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®å ´åˆ
            attributes = getattr(cloud_event, 'attributes', None)
            if attributes and isinstance(attributes, dict):
                event_type = attributes.get('type', 'unknown')
                event_source = attributes.get('source', 'unknown')
            else:
                event_type = getattr(cloud_event, 'type', 'unknown')
                event_source = getattr(cloud_event, 'source', 'unknown')
            event_data = getattr(cloud_event, 'data', None) or getattr(cloud_event, 'payload', None)
        
        logger.info(f"ğŸ”” CloudEvent type: {event_type}")
        logger.info(f"ğŸ”” CloudEvent source: {event_source}")
        logger.info(f"ğŸ“¦ CloudEvent.dataã®å‹: {type(event_data)}")
        
        # CloudEvent.dataãŒNoneã®å ´åˆã®å‡¦ç†
        if event_data is None:
            logger.error("âŒ CloudEvent.dataãŒNoneã§ã™")
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®å ´åˆã€ç›´æ¥å±æ€§ã«ã‚¢ã‚¯ã‚»ã‚¹ã‚’è©¦è¡Œ
            if hasattr(cloud_event, 'data'):
                logger.info("ğŸ“¦ cloud_event.dataå±æ€§ã‚’ç›´æ¥ç¢ºèª...")
                event_data = cloud_event.data
                logger.info(f"ğŸ“¦ ç›´æ¥å–å¾—ã—ãŸevent_dataã®å‹: {type(event_data)}")
            else:
                logger.error("âŒ CloudEventã«dataå±æ€§ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {"status": "error", "reason": "no data in cloud_event"}
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèª
        if event_data:
            logger.info(f"ğŸ“¦ CloudEvent.dataã®å†…å®¹ï¼ˆæœ€åˆã®1000æ–‡å­—ï¼‰: {str(event_data)[:1000]}")
        
        # Cloud Storage v2ä»•æ§˜ã®CloudEventãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’å‡¦ç†
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸJSONæ–‡å­—åˆ—ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ï¼‰
        if isinstance(event_data, str):
            logger.info("ğŸ“¦ event_dataã¯æ–‡å­—åˆ—å‹ã§ã™ã€‚Base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’è©¦è¡Œ...")
            try:
                # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’è©¦è¡Œ
                decoded_bytes = base64.b64decode(event_data)
                decoded_str = decoded_bytes.decode('utf-8')
                event_data = json.loads(decoded_str)
                logger.info("âœ… Base64ãƒ‡ã‚³ãƒ¼ãƒ‰æˆåŠŸ")
                logger.info(f"ğŸ“¦ ãƒ‡ã‚³ãƒ¼ãƒ‰å¾Œã®event_data: {json.dumps(event_data, ensure_ascii=False)}")
            except Exception as decode_error:
                # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã€JSONæ–‡å­—åˆ—ã¨ã—ã¦ç›´æ¥ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
                logger.info("âš ï¸ Base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã€‚JSONæ–‡å­—åˆ—ã¨ã—ã¦ç›´æ¥ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ...")
                try:
                    event_data = json.loads(event_data)
                    logger.info("âœ… JSONæ–‡å­—åˆ—ã¨ã—ã¦ç›´æ¥ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
                except json.JSONDecodeError:
                    logger.error(f"âŒ CloudEventãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {decode_error}")
                    logger.error(f"   ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰: {event_data[:500] if len(event_data) > 500 else event_data}")
                    return {"status": "error", "reason": "decode error", "details": str(decode_error)}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ—¢ã«è¾æ›¸å½¢å¼
        if isinstance(event_data, dict):
            logger.info("ğŸ“¦ event_dataã¯è¾æ›¸å½¢å¼ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º...")
            # ãƒã‚±ãƒƒãƒˆåã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ï¼ˆè¤‡æ•°ã®ã‚­ãƒ¼åã«å¯¾å¿œï¼‰
            bucket = event_data.get('bucket') or event_data.get('bucketId') or ''
            name = event_data.get('name') or event_data.get('object') or event_data.get('file') or ''
            
            logger.info(f"ğŸ“ æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿: bucket={bucket}, name={name}")
            
            if not bucket or not name:
                logger.error(f"âŒ CloudEventãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨: bucket={bucket}, name={name}")
                logger.error(f"   å®Œå…¨ãªevent_data: {json.dumps(event_data, ensure_ascii=False)}")
                logger.error(f"   åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼: {list(event_data.keys())}")
                return {"status": "error", "reason": "incomplete event data", "bucket": bucket, "name": name}
            
            # process_videoé–¢æ•°ã«æ¸¡ã™å½¢å¼ã«å¤‰æ›
            video_data = {
                'bucket': bucket,
                'name': name
            }
            
            logger.info(f"ğŸ“ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {name} (ãƒã‚±ãƒƒãƒˆ: {bucket})")
            
            # ãƒ‘ã‚¹ã®æ¤œè¨¼ï¼ˆäº‹å‰ãƒã‚§ãƒƒã‚¯ï¼‰
            if not name.startswith('videos/'):
                logger.warning(f"âš ï¸ ãƒ‘ã‚¹ãŒvideos/ã§å§‹ã¾ã‚‰ãªã„: {name}")
                logger.warning(f"   å®Œå…¨ãªevent_data: {json.dumps(event_data, ensure_ascii=False)}")
                return {"status": "skipped", "reason": "not a video file", "file_path": name}
            
            try:
                logger.info("ğŸš€ process_videoé–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¾ã™...")
                result = process_video(video_data, None)
                logger.info(f"âœ… å‡¦ç†å®Œäº†: {json.dumps(result, ensure_ascii=False)}")
                logger.info("=" * 80)
                return result
            except Exception as process_error:
                logger.error(f"âŒ process_videoå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {process_error}")
                traceback.print_exc()
                logger.info("=" * 80)
                return {"status": "error", "reason": "processing error", "details": str(process_error)}
        else:
            logger.error(f"âŒ äºˆæœŸã—ãªã„CloudEventãƒ‡ãƒ¼ã‚¿å½¢å¼: {type(event_data)}")
            logger.error(f"   ãƒ‡ãƒ¼ã‚¿å†…å®¹: {str(event_data)[:500]}")
            logger.info("=" * 80)
            return {"status": "error", "reason": "unexpected event data format", "type": str(type(event_data))}
                
    except Exception as e:
        logger.error(f"âŒ CloudEventå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"   CloudEventå‹: {type(cloud_event)}")
        logger.error(f"   CloudEventå†…å®¹: {str(cloud_event)[:500]}")
        traceback.print_exc()
        logger.info("=" * 80)
        return {"status": "error", "reason": str(e)}


# ãƒ†ã‚¹ãƒˆç”¨ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ï¼‰
if __name__ == '__main__':
    test_data = {
        'name': 'videos/test_user/1234567890-test.mp4',
        'bucket': 'aikaapp-584fa.firebasestorage.app'
    }
    
    result = process_video(test_data, None)
    print(json.dumps(result, indent=2, ensure_ascii=False))
